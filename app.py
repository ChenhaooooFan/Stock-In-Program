import streamlit as st
import pandas as pd
import re

st.set_page_config(page_title="NailVesta å…¥åº“åŒ¹é…å·¥å…·ï¼ˆæ”¯æŒ PDF å¤šè¡¨é¢„è§ˆï¼‰", layout="wide")
st.title("ğŸ’… NailVesta å…¥åº“åŒ¹é…å·¥å…·ï¼ˆå…¥åº“æ•°é‡è¾“å‡ºï½œæ”¯æŒ PDF å¤šè¡¨é¢„è§ˆï¼‰")

# ============== ä¸Šä¼ æ–‡ä»¶åŒº ==============
stock_file = st.file_uploader("ğŸ“¦ ä¸Šä¼ åº“å­˜è¡¨ï¼ˆå¿…é¡»åŒ…å«ã€SKUç¼–ç ã€åˆ—ï¼Œå¦‚ NPX014-Sï¼‰", type=["csv", "xlsx"])
entry_file = st.file_uploader("ğŸ“ ä¸Šä¼ å…¥åº“è¡¨ï¼ˆæ”¯æŒ CSV/XLSX/PDFï¼‰", type=["csv", "xlsx", "pdf"])

# ============== å·¥å…·å‡½æ•° ==============
def read_stock(file):
    if file.name.endswith(".csv"):
        return pd.read_csv(file, encoding="utf-8-sig")
    else:
        return pd.read_excel(file)

def _normalize_header(s):
    if s is None: return ""
    s = str(s).strip().replace("\n","").replace(" ","")
    s = s.replace("ï¼ˆ","(").replace("ï¼‰",")")
    return s

def clean_base(s):
    s = str(s).strip()
    s = re.sub(r"\s+","", s)
    s = s.replace("ï¼ˆ","(").replace("ï¼‰",")")
    s = re.sub(r"(è¡¥å¯„|åŠ å•|é‡å‘|å¤‡æ³¨).*","", s)
    m = re.search(r"[A-Z]{2,4}\d{3}", s)
    return m.group(0) if m else s

# ============== PDF è§£æï¼ˆå¤šè¡¨é¢„è§ˆï¼‰ ==============
def extract_tables_from_pdf(file_obj, page_from=1, page_to=9999, keyword=""):
    import pdfplumber
    tables = []
    with pdfplumber.open(file_obj) as pdf:
        total_pages = len(pdf.pages)
        p1, p2 = max(1, int(page_from)), min(total_pages, int(page_to))
        for i in range(p1-1, p2):
            page = pdf.pages[i]
            if keyword:
                head_text = (page.extract_text() or "")[:300]
                if keyword not in head_text:
                    continue
            page_tables = page.extract_tables() or []
            for tbl in page_tables:
                if tbl and len(tbl) > 1:
                    tables.append(tbl)
    return tables

def convert_table_to_df(tbl):
    header = [_normalize_header(x) for x in tbl[0]]
    width = len(header)
    rows = []
    for r in tbl[1:]:
        rr = list(r) + [""] * max(0, width - len(r))
        rows.append(rr[:width])
    df = pd.DataFrame(rows, columns=header)
    # æ ‡å‡†åŒ–åˆ—å
    df.columns = [c.lower() for c in df.columns]
    # æ‰¾åˆ—
    sku_col = next((c for c in df.columns if "sku" in c or "å°ç›’å­" in c or "ä¸‹å•ç¼–å·" in c), None)
    s_col   = next((c for c in df.columns if c.startswith("s")), None)
    m_col   = next((c for c in df.columns if c.startswith("m")), None)
    l_col   = next((c for c in df.columns if c.startswith("l")), None)
    if not all([sku_col, s_col, m_col, l_col]):
        raise ValueError(f"è¯¥è¡¨æ ¼æœªæ‰¾åˆ°å®Œæ•´åˆ—ï¼Œç°æœ‰åˆ—ï¼š{df.columns}")
    out = df[[sku_col, s_col, m_col, l_col]].copy()
    out.columns = ["SKU ç¼–ç ", "Sæ•°é‡", "Mæ•°é‡", "Læ•°é‡"]
    out["SKU ç¼–ç "] = out["SKU ç¼–ç "].apply(clean_base)
    for c in ["Sæ•°é‡","Mæ•°é‡","Læ•°é‡"]:
        out[c] = pd.to_numeric(out[c], errors="coerce").fillna(0).round().clip(lower=0).astype(int)
    return out

def build_entry_map(entry_df):
    entry_map = {}
    for _, row in entry_df.iterrows():
        base = str(row["SKU ç¼–ç "]).strip()
        for size, col in zip(["S","M","L"], ["Sæ•°é‡","Mæ•°é‡","Læ•°é‡"]):
            qty = int(row[col])
            if qty > 0:
                full = f"{base}-{size}"
                entry_map[full] = entry_map.get(full, 0) + qty
    return entry_map

# ============== ä¸»æµç¨‹ ==============
if stock_file and entry_file:
    try:
        stock_df = read_stock(stock_file)
        if "SKUç¼–ç " not in stock_df.columns:
            st.error("âŒ åº“å­˜è¡¨ç¼ºå°‘ã€SKUç¼–ç ã€åˆ—")
            st.stop()
        stock_skus = stock_df["SKUç¼–ç "].dropna().astype(str).str.strip().tolist()

        if entry_file.name.lower().endswith(".pdf"):
            with st.sidebar:
                st.header("PDF è§£æèŒƒå›´")
                page_from = st.number_input("èµ·å§‹é¡µ", min_value=1, value=1)
                page_to   = st.number_input("ç»“æŸé¡µ", min_value=1, value=50)
                keyword   = st.text_input("æ ‡é¢˜å…³é”®è¯è¿‡æ»¤ï¼ˆå¯é€‰ï¼‰", value="")

            tables = extract_tables_from_pdf(entry_file, page_from, page_to, keyword)
            if not tables:
                st.error("âš ï¸ åœ¨é€‰å®šèŒƒå›´å†…æœªè¯†åˆ«åˆ°è¡¨æ ¼")
                st.stop()

            # æ˜¾ç¤ºå€™é€‰è¡¨æ ¼
            st.subheader("ğŸ” PDF è¡¨æ ¼é¢„è§ˆ")
            options = [f"Table #{i+1}" for i in range(len(tables))]
            choice = st.selectbox("é€‰æ‹©è¦ä½¿ç”¨çš„è¡¨æ ¼", options)
            idx = options.index(choice)
            entry_df_raw = convert_table_to_df(tables[idx])
            st.dataframe(entry_df_raw.head(20), use_container_width=True)

        else:
            entry_df_raw = read_stock(entry_file)

        # æ„å»ºæ˜ å°„
        entry_map = build_entry_map(entry_df_raw)

        # åŒ¹é…
        results, unmatched, total_in = [], [], 0
        for sku in stock_skus:
            qty = entry_map.get(sku, "")
            results.append((sku, qty))
            if qty == "":
                unmatched.append(sku)
            else:
                total_in += qty
        result_df = pd.DataFrame(results, columns=["SKUç¼–ç ","å…¥åº“æ•°é‡"])

        st.success(f"âœ… åŒ¹é…å®Œæˆï¼åŒ¹é…åˆ° {result_df['å…¥åº“æ•°é‡'].replace('',0).astype(int).gt(0).sum()} ä¸ª SKUï¼Œç´¯è®¡ {total_in} ä»¶")
        st.dataframe(result_df, use_container_width=True)

        st.markdown("### ğŸ“‹ å¯å¤åˆ¶å…¥åº“æ•°é‡åˆ—ï¼ˆé¡ºåºå¯¹é½åº“å­˜è¡¨ï¼‰")
        st.code("\n".join([str(x) for x in result_df["å…¥åº“æ•°é‡"].tolist()]), language="text")

        st.download_button(
            "ğŸ“¥ ä¸‹è½½å…¥åº“æ•°é‡ CSV",
            result_df.to_csv(index=False).encode("utf-8-sig"),
            "NailVesta_å…¥åº“æ•°é‡.csv",
            "text/csv"
        )
        if unmatched:
            st.warning("âš ï¸ æœªåŒ¹é…åˆ°çš„ SKU ç¤ºä¾‹ï¼š\n" + "\n".join(unmatched[:10]))

    except Exception as e:
        st.error(f"âŒ å‡ºé”™ï¼š{e}")
